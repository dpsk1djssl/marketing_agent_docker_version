import streamlit as st
import asyncio

from mcp.client.stdio import stdio_client
from mcp import ClientSession, StdioServerParameters
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from PIL import Image
from pathlib import Path

# í™˜ê²½ë³€ìˆ˜
ASSETS = Path("assets")
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]

system_prompt = (
    "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë§ˆì¼€íŒ… ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\n"
    "- ì¶œë ¥ì€ ë³´ê¸° ì¢‹ì€ Markdown í˜•ì‹ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.\n"
    "- ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”: # ìš”ì•½ â†’ ## í•µì‹¬ ì¸ì‚¬ì´íŠ¸(ë¶ˆë¦¿) â†’ ## ì¶”ì²œ ì±„ë„(í‘œ) â†’ ## ì‹¤í–‰ ê°€ì´ë“œ(ë¶ˆë¦¿) â†’ ## ë°ì´í„° ê·¼ê±°(í‘œ).\n"
    "- í‘œëŠ” 2~5 ì»¬ëŸ¼ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ê¸´ ë¬¸ì¥ì€ ì¤„ì—¬ì£¼ì„¸ìš”.\n"
    "- í•µì‹¬ë§Œ ì§§ê³  ê°„ê²°í•˜ê²Œ(ë¶ˆí•„ìš”í•œ ì¥í™©í•œ ì„¤ëª… ê¸ˆì§€).\n"
    "- ìˆ«ìëŠ” ë‹¨ìœ„ì™€ ê¸°ì¤€(%)ë¥¼ ëª…í™•íˆ í‘œì‹œí•˜ê³ , ë¶ˆí™•ì‹¤í•˜ë©´ í‘œê¸°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
    "ê°€ë§¹ì ëª…ì„ ë°›ì•„ ë°©ë¬¸ ê³ ê° í˜„í™©ì„ ë¶„ì„í•˜ê³ , ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë§ˆì¼€íŒ… ì±„ë„ê³¼ ë©”ì‹œì§€ë¥¼ ì¶”ì²œí•˜ì„¸ìš”."
)
greeting = "ë§ˆì¼€íŒ…ì´ í•„ìš”í•œ ê°€ë§¹ì ì„ ì•Œë ¤ì£¼ì„¸ìš”  \n(ì¡°íšŒê°€ëŠ¥ ì˜ˆì‹œ: ë™ëŒ€*, ìœ ìœ *, ë˜¥íŒŒ*, ë³¸ì£½*, ë³¸*, ì›ì¡°*, í¬ë§*, í˜ì´*, Hì»¤*, ì¼€í‚¤*)"

# Streamlit App UI
@st.cache_data 
def load_image(name: str):
    return Image.open(ASSETS / name)

st.set_page_config(page_title="2025ë…„ ë¹…ì½˜í…ŒìŠ¤íŠ¸ AIë°ì´í„° í™œìš©ë¶„ì•¼ - ë§›ì§‘ì„ ìˆ˜í˜¸í•˜ëŠ” AIë¹„ë°€ìƒë‹´ì‚¬")

def clear_chat_history():
    st.session_state.messages = [SystemMessage(content=system_prompt), AIMessage(content=greeting)]

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.image(load_image("shc_ci_basic_00.png"), width='stretch')
    st.markdown("<p style='text-align: center;'>2025 Big Contest</p>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center;'>AI DATA í™œìš©ë¶„ì•¼</p>", unsafe_allow_html=True)
    st.write("")
    col1, col2, col3 = st.columns([1,2,1])  # ë¹„ìœ¨ ì¡°ì • ê°€ëŠ¥
    with col2:
        st.button('Clear Chat History', on_click=clear_chat_history)

# í—¤ë”
st.title("ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ğŸ”‘ ë¹„ë°€ìƒë‹´ì†Œ")
st.subheader("#ìš°ë¦¬ë™ë„¤ #ìˆ¨ì€ë§›ì§‘ #ì†Œìƒê³µì¸ #ë§ˆì¼€íŒ… #ì „ëµ .. ğŸ¤¤")
st.image(load_image("image_gen3.png"), width='stretch', caption="ğŸŒ€ ë¨¸ë¦¬ì•„í”ˆ ë§ˆì¼€íŒ… ğŸ“Š ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?")
st.write("")

# ë©”ì‹œì§€ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        SystemMessage(content=system_prompt),
        AIMessage(content=greeting)
    ]

# ì´ˆê¸° ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.write(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.write(message.content)

def render_chat_message(role: str, content: str):
    with st.chat_message(role):
        st.markdown(content.replace("<br>", "  \n"))

# LLM ëª¨ë¸ ì„ íƒ
llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",  # ìµœì‹  Gemini 2.5 Flash ëª¨ë¸
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1
    )

# MCP ì„œë²„ íŒŒë¼ë¯¸í„°(í™˜ê²½ì— ë§ê²Œ ëª…ë ¹ ìˆ˜ì •)
server_params = StdioServerParameters(
    command="uv",
    args=["run","mcp_server.py"],
    env=None
)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
async def process_user_input():
    """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” async í•¨ìˆ˜"""
    async with stdio_client(server_params) as (read, write):
        # ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ClientSessionì„ ë§Œë“¤ê³ 
        async with ClientSession(read, write) as session:
            # ì„¸ì…˜ì„ initialize í•œë‹¤
            await session.initialize()

            # MCP íˆ´ ë¡œë“œ
            tools = await load_mcp_tools(session)

            # ì—ì´ì „íŠ¸ ìƒì„±
            agent = create_react_agent(llm, tools)

            # ì—ì´ì „íŠ¸ì— ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
            agent_response = await agent.ainvoke({"messages": st.session_state.messages})
            
            # AI ì‘ë‹µì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            ai_message = agent_response["messages"][-1]  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AI ì‘ë‹µ

            return ai_message.content
            

# ì‚¬ìš©ì ì…ë ¥ ì°½
if query := st.chat_input("ê°€ë§¹ì  ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append(HumanMessage(content=query))
    render_chat_message("user", query)

    with st.spinner("Thinking..."):
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
            reply = asyncio.run(process_user_input())
            st.session_state.messages.append(AIMessage(content=reply))
            render_chat_message("assistant", reply)
        except* Exception as eg:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            for i, exc in enumerate(eg.exceptions, 1):
                error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ #{i}: {exc!r}"
                st.session_state.messages.append(AIMessage(content=error_msg))
                render_chat_message("assistant", error_msg)
